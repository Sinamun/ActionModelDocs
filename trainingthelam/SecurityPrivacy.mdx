---
title: 'Security & Privacy'
description: 'Security & Privacy'
---
https://docs.google.com/document/d/1sz0EBAypvg4WpcKwY6UTEvp6aYxVio1qcpjt4fCh4kM/edit?tab=t.0#heading=h.t9caixdlywo7

Security & Privacy
Training the Action Model should never come at the expense of your privacy.
Thatâ€™s why our system is designed with data sovereignty and user control at its core - across both the Public and Private models.
Public General Action Model
When contributing to the Public Action Model (the general-purpose agent for everyone) your data is protected through:
Local Data Sanitisation
Personal data is filtered and removed directly on your device before it ever leaves your environment.


PII Obfuscation
Names, emails, addresses, and other personally identifiable information are automatically masked or excluded from training sets.


Secure Abstraction of Inputs
Specific user inputs are replaced with generalised tokens or variables (e.g. <<username>>, <<credit_card_last4>>), preserving structure without exposing content.
The result is a dataset that teaches the Action Model how to act, without ever learning who you are.
Private Action Model
When training your Private Action Model, a deeper level of insight is required to provide real autonomy. This includes:
Full Workflow Visibility
Your sequences are captured in full fidelity - including variable inputs and context - so the AI can learn how to act exactly as you would.


Contextual Awareness
Decision logic, input timing, workflow triggers, and variable dependencies are preserved to ensure your AI makes choices aligned with your preferences.


Local Control
All sensitive data remains within your own ecosystem. The model is trained in your environment, for your environment - never shared, never exposed.


The Private Action Model learns deeply, but it does so privately.
