
# The Action Model (/the-action-model)
What is the Action Model (/the-action-model/what-is-the-action-model)
1 Billion jobs will be Displaced (/the-action-model/1-billion-jobs-will-be-displaced)
Big Tech Owns 99% of the AI future (/the-action-model/big-tech-owns-99-percent-of-ai-future)
Action Model is the Uprising (/the-action-model/action-model-is-the-uprising)
How to be part of the AI Future (/the-action-model/how-to-be-part-of-the-ai-future)


# Actionist.ai (/actionist)
Actionist Overview (/actionist/actionist-overview)
App Demos / Examples (/actionist/app-demos-and-examples)
Agents & Workflows (/actionist/agents-and-workflows)
Cloud VPC (/actionist/cloud-vpc)
Actionist Browser Extension
Agent Calendar (/actionist/agent-calendar-schedules)
Memories (/actionist/agent-memory)
History (/actionist/agent-history)
Tool Usage (/actionist/agent-tool-usage)
Triggers (/actionist/triggers)


# Marketplace (/marketplace)
Marketplace Overview (/marketplace/marketplace-overview)
Marketplace Bounties (/marketplace/marketplace-bounties)
Revenue Generation (/marketplace/revenue-generation)
Featured Workflows and Reputation (/marketplace/marketplace-reputation-and-featured-workflows)
Agent Marketplace (/marketplace/agent-marketplace)


# The Large Action Model (LAM) (/the-large-action-model)
Training the LAM (/the-large-action-model-lam/training-the-large-action-model)
Browser Extension Overview (/the-large-action-model-lam/browser-extension-overview)
Security & Privacy (/the-large-action-model-lam/security-and-privacy

# Tokenomics (/tokenomics)
Token Utility ($LAM) (tokenomics/token-utility)
Point Tiers and Epochs (tokenomics/training-to-earn-tokens
Marketplace Distributions (tokenomics/marketplace-distributions)
Training & Marketplace Bounties (tokenomics/training-and-marketplace-bounties)
Referrals, Affiliates & Quests (tokenomics/referrals-and-affiliates)
Token Economics (tokenomics/token-economics)









======================================
======================================
======================================



# The Action Model (/the-action-model) {#the-action-model-(/the-action-model)}

## What is the Action Model (/the-action-model/what-is-the-action-model) {#what-is-the-action-model-(/the-action-model/what-is-the-action-model)}

- High level summary  
- Link to other pages





## 1 Billion jobs will be Displaced (/the-action-model/1-billion-jobs-will-be-displaced) {#1-billion-jobs-will-be-displaced-(/the-action-model/1-billion-jobs-will-be-displaced)}

- 1 billion people employed to work behind computers  
- [https://fortune.com/2025/08/19/morgan-stanley-920-billion-sp-500-savings-ai-agentic-robots-jobs/](https://fortune.com/2025/08/19/morgan-stanley-920-billion-sp-500-savings-ai-agentic-robots-jobs/)

Almost all of these jobs are Non technical roles, which AI can very simply replace

- \*\* find research about the type of computer jobs  
- 30% of EU jobs behind computer   
  - [https://ec.europa.eu/eurostat/web/products-eurostat-news/w/ddn-20230627-1](https://ec.europa.eu/eurostat/web/products-eurostat-news/w/ddn-20230627-1)

Table about how many workers there are.

| Metric | Number | Percentage | Source | URL |
| ----- | ----- | ----- | ----- | ----- |
| Knowledge Workers Globally | 644–997 million | 19.6–30.4% of global employment | UN/ILO 2023 | [PDF – UN/ILO 2023](https://sdgs.un.org/sites/default/files/2023-05/B59%20-%20Berg%20-%20Automation%20hits%20the%20knowledge%20worker%20ChatGPT%20and%20the%20future%20of%20work.pdf) |
| Knowledge Workers (Alternative) | 1+ billion | \~30% of workforce | Gartner/Forbes | [AskWonder Report](https://askwonder.com/research/knowledge-worker-market-size-hyayzm1p4) |
| Global Internet Users | 5.65 billion | 68.7% of world population | DataReportal 2025 | [DataReportal 2025](https://datareportal.com/global-digital-overview) |

These people are employed use three things: 1\. to look at the screen, 2\. use a mouse 3\. and keyboard. 

AI is now capable of doing exactly this, and as the technology advances, AI will almost entirely displace these roles \- anything you can do with these 3 things, AI will be able to do too.

Businesses are always opting for profit over everything else \- if an AI Agent does the work of 3 people, with \-95% less cost, all businesses will use them.

This means that hundreds of millions of jobs will be displayed in the next few years, with the workload being shifted directly to AI companies providing these services.

Unfortunately, 99% of this is will be owned by Big Tech (see [Big Tech Owns 99% of the AI future](#big-tech-owns-99%-of-the-ai-future-\(/the-action-model/big-tech-owns-99-percent-of-ai-future\)))









## Big Tech Owns 99% of the AI future (/the-action-model/big-tech-owns-99-percent-of-ai-future) {#big-tech-owns-99%-of-the-ai-future-(/the-action-model/big-tech-owns-99-percent-of-ai-future)}

- deep tech  
  - This technology is very hard to train  
  - Training data is extremely scarce  
  - The data requirements for a Large Action Model is significantly harder to attain than an LLM  
  - Unlike Language Models (LLMs) where the training data can simply be downloaded from the internet (Books, Journals, Scientific papers, articles, blogs, social media etc)  
  - Large Action Models need path data to train \- this doesn’t exist organically to be scraped, it needs to be collected with intent. See [Training data required](#training-the-lam-\(/the-large-action-model-lam/training-the-large-action-model\)) section for more information.  
  -   
- Therefore, Action Models are Significantly more complicated than making Language Models (LLMs)  
- There is a much deeper moat in creating Action Models  
- This reduces the number of participants or competitors in this space.  
- This will make the big tech companies (Google, Microsoft, OpenAI, Claude etc) the main players providing this software.

- As hundreds of millions of jobs get displaced by AI (See [1 Billion jobs will be Displaced](#1-billion-jobs-will-be-displaced-\(/the-action-model/1-billion-jobs-will-be-displaced\))), the money flow will be diverted from people (employed) to Big Tech (Agents)

- Unfortunately, your data is being taken to train all of this, and you aren’t given any share of it. We believe that AI should be owned by the people who contribute to it.   
-   
- With Action Model, you can own a stake in AI. Action Model is the Resistance \- see [Action Model is the Uprising](#action-model-is-the-uprising-\(/the-action-model/action-model-is-the-uprising\)))

## Action Model is the Uprising (/the-action-model/action-model-is-the-uprising) {#action-model-is-the-uprising-(/the-action-model/action-model-is-the-uprising)}

- We believe that this disruptive AI should be owned by all of us \- especially the people who helped it grow, helped train it, or contributed to it.

- By contributing to the platform   
  - Learn more about contributing: (Link to [How to be part of the AI Future](#how-to-be-part-of-the-ai-future-\(/the-action-model/how-to-be-part-of-the-ai-future\)))  
  - Show 4 boxes (Marketplace, Referrals, Quests, Training) and link them to the correct headings in [How to be part of the AI Future](#how-to-be-part-of-the-ai-future-\(/the-action-model/how-to-be-part-of-the-ai-future\)))  
- You receive tokens as a reward.  
-   
- These tokens act as your share in the AI future, this is your stake in the future of AI  
- These tokens have two distinct mechanisms behind them:  
  - Utility  
    - Tokens are the central fuel and utility in the AI (see [Token Utility ($LAM)](#token-utility-\($lam\)-\(tokenomics/token-utility\)))  
    - These tokens are consumed when anyone uses the Action Model  
    - Therefore, these tokens have an inherent value, as they are consumed by the ecosystem to run the AI.  
    - 

  - DAO  
    - Tokens will run the DAO  
    - You will have part of the AI future  
    - There will be governance and voting mechanics through the DAO






## How to be part of the AI Future (/the-action-model/how-to-be-part-of-the-ai-future) {#how-to-be-part-of-the-ai-future-(/the-action-model/how-to-be-part-of-the-ai-future)}

By contributing to the Action Model, you will receive tokens, which are you ownership stake of the AI future.

These are the four main ways to contribute to the Action Model, to the Uprising.

Further explanation:

- Marketplace (Create Workflows and Agents)  
  - By creating workflows and agents, publishing them to the marketplace, you will receive tokens.  
  - Link to [Marketplace Overview](#marketplace-overview-\(/marketplace/marketplace-overview\))  
  - Every time your workflows are used by businesses or customers, you receive more tokens.

- Train the LAM  
  - Instead of your data being stolen by Big Tech to train their AI, without you being paid  
  - you can contribute in the background to the Action Model.  
  - It takes 60 seconds to setup, and then you earn tokens in the background.  
  - You are helping build one of the best LAM’s in the world  
  - Read more: Browser Extension Overview (/the-large-action-model-lam/browser-extension-overview)

- Referrals  
  - By inviting more people to the Action Model, you are growing the resistance. You are rewarded for each person you invite (points and affiliate %).  
  - You also receive a share of everyone they invite too (3 layers)  
  - Read more here: Referrals, Affiliates & Quests (tokenomics/referrals-and-affiliates)

- Spread the message  
  - By spreading the word about the Resistance, you are helping to grow the Action Model.  
  - As a result of this, you are rewarded with tokens  
  - Read more about this here:  Referrals, Affiliates & Quests (tokenomics/referrals-and-affiliates)







======================================
======================================
======================================







# Actionist.ai (/actionist) {#actionist.ai-(/actionist)}

## Actionist Overview (/actionist/actionist-overview) {#actionist-overview-(/actionist/actionist-overview)}

Intro

- Actionist is the Action Models native desktop application.   
- The app controls the computers mouse and keyboard  
- By looking at the screen, it knows exactly what the environment is  
- The LAM can then decide what action to take next

App Demos / Use-cases

- You can see some of the use-cases here: [App Demos / Examples (/actionist/app-demos-and-examples)](#app-demos-/-examples-\(/actionist/app-demos-and-examples\))

Availability

- The application is available in Mac and Windows (Linux coming soon)  
  - It is in private beta at the moment. Please contact the Administration team for early access

Here are some example use-cases of the Actionist Desktop application running.

Action Loop

- By looking at the screen, it can understand the context of what is happening, using the LAM (Large Action Model) to decide what Action to take next.  
- 

[IMAGE (ACTION LOOP IMAGE)](https://www.figma.com/design/23Azr0HhLyUGNgVe74zD9f/LAM-Pitch-Decks?node-id=3968-5487&t=BKnVqnQS4uZPsBac-11)

- This Action Loop happens on repeat, taking one Action at a time, until either:  
  - The AI determines that the goal has been reached  
  - The time allotment has been reached (see [Agent Calendar](#agent-calendar-\(/actionist/agent-calendar-schedules\)))  
  - The workflow initiates a different workflow

LAM API (Large Action Model)

- The Actionist app uses the LAM API (See [API Partners](#api-partners-\(/partnerships/api-partners\))) to utilise the Large Action Model and launch the Action Loop  
- Each of these Actions consumes the $LAM token as Fuel, which is the central utility of the ecosystem.  
- The $LAM consumed during the Action Loop goes through a distribution and burning mechanism. Read more here: [Marketplace Distributions](#marketplace-distributions-\(tokenomics/marketplace-distributions\)) and [Token Economics](#token-economics-\(tokenomics/token-economics\))

[IMAGE: ACTION LOOP MORE DETAIL](https://www.figma.com/design/23Azr0HhLyUGNgVe74zD9f/LAM-Pitch-Decks?node-id=3968-5530&t=BKnVqnQS4uZPsBac-11)

Actionist Functionalty  
(Image with title and 1 sentence description)

- Agents  
  - A specific role or department  
  - Link to: [Agents & Workflows](#agents-&-workflows-\(/actionist/agents-and-workflows\))  
- Workflows  
  - Individual tasks that the Agent will complete  
  - Link to: [Agents & Workflows](#agents-&-workflows-\(/actionist/agents-and-workflows\))  
- Cloud VPC  
  - 24/7 Cloud Mac or Windows for your Agent  
  - Link to: [Cloud VPC](#cloud-vpc-\(/actionist/cloud-vpc\))  
- Agent Calendar / Schedules  
  - Like your staff, Agents also have Calendars of what they are doing  
  - Link to: [Agent Calendar](#agent-calendar-\(/actionist/agent-calendar-schedules\))  
- Memories  
  - How to use your platforms and your preferences  
  - Link to: [Memories](#memories-\(/actionist/agent-memory\))  
- History  
  - Everything your Agent(s) have done, for your visibility and for Agent Context  
  - Link to: [History](#history-\(/actionist/agent-history\))  
- Tool Usage  
  - Allow the Agents to connect to tools, functions and scripts  
  - Link to: [Tool Usage](#tool-usage-\(/actionist/agent-tool-usage\))

System settings:

- After logging, user will be prompted to provide access to certain permissions  
- [ADD IMAGE:](https://www.figma.com/design/23Azr0HhLyUGNgVe74zD9f/LAM-Pitch-Decks?node-id=3968-5484&t=BKnVqnQS4uZPsBac-11%20) 







## App Demos / Examples (/actionist/app-demos-and-examples) {#app-demos-/-examples-(/actionist/app-demos-and-examples)}

There are \~1 billion people who are employed to work behind a computer.

These people are all using 3 things:

1. Looking at the screen  
2. Using the mouse  
3. Using the keyboard

All of the jobs and responsibilities that these 1 billion humans undertake, is all executed by using these 3 items.

AI can now utilise all 3 of these.

The result is that Computer Agents (Like Action Models Actionist) will be able to do all of this work, providing a nearly infinite number of use-cases.

Here are a few use-cases:  
\*\*Use example youtube embed links for these three videos \- I will replace manually\*\*

- Title: Linkedin Automation  
  - TAG: Marketing, Lead Generation  
  - Actions:  
    - Scrolls through Linkedin  
    - Looks for AI Related content  
    - Leaves engaging, relative and positive comments  
  - Description: This workflow will scroll through linkedin, looking at the posts in your feed and engaging with posts that are relevant to you. You could extend this workflow into lead generation so that it messages the users who also engaged in the post.

- Title: Content Creation \+ Social Media Publishing  
  - TAG: Social Media Growth  
  - Actions:  
    - Navigate to Gemini  
    - Select Video Generation  
    - Create a prompt (Crypto ASMR related)  
    - Wait for Video to be created  
    - Download the Video  
    - Navigate to Instagram  
    - Upload video to Instagram  
    - Publish the Reel  
    - Navigate to [X.com](http://X.com)  
    - Write a Tweet  
    - Upload video to X  
    - Publish the post to X  
  - Description: Schedule this workflow to run multiple times a day, growing your Social Media accounts. This would automate the work of Social Media Managers.

- Title: Qualify Candidates, book interviews and create Job Offer  
  - TAG: HR, Operations  
  - Actions:  
1. Open CV  
2. Review against criteria  
3. Move to Interview or Reject folder  
4. Loop to Step 1 until all CVs have been reviewed  
5. Open Google Calendar  
6. Create interview booking slot  
7. Copy booking link  
8. Open Gmail  
9. Draft new email to candidates  
10. Write email and paste booking link   
11. Open Google Drive  
12. Create new  
    - Description: This workflow would save weeks of time reviewing CV’s for new job roles, triaging them, booking meetings and create contracts. This would automate huge portions of HR Staff work.

- Title: CRM / Email Automation  
  - TAG: Sales, Lead Generation  
  - Actions  
1. Open ReachInbox (or CRM)  
2. Upload CSV of Sales Leads  
3. Attach CSV to a Campaign  
4. Configure Campaign settings  
5. Ask Human to confirm before launching campaign  
6. Launch Email Outreach Campaign  
- Description: As part of a sequence of workflows (gather emails, create sheet, attach to ReachInbox, Review campaign), this workflow is for Marketing Agencies with many clients.








## Agents & Workflows (/actionist/agents-and-workflows) {#agents-&-workflows-(/actionist/agents-and-workflows)}

- N8n, zapier, [make.com](http://make.com) \- ALL technical, excludes 99% of the population  
- Actionist workflows are all in human language, very simple to understand  
  - IMAGE OF WORKFLOW STEPS

Configuration of a workflow:

- Variables  
  - Variables that the AI needs to look out for. Variables can also be provided by the user, gathered from different sources, or passed in as a parameter from a different workflow)  
- Workflow Steps  
  - These are the sequence of steps required for the Agent to follow (all in human language)  
  - This can contain Loops, IF Conditions, Branches etc  
- Rules  
  - If the AI needs to follow certain rules or conditions  
- Success Conditions  
  - When should the AI consider a successful execution \- this is what the Agent needs to work towards, and also when it knows it has finished the workflow  
- Human Confirmation  
  - If you need the Agent to ask the human what to do, or to confirm a certain action or checkpoint. The Agent will message in the chat and wait for the humans response  
  - In the future, this will be linked to messaging software such as Telegram and Whatsapp, for rapid confirmation  
  - There is also an ‘autopilot’ mode in which all human confirmation is bypassed automatically (use with caution)  
- Memories  
  - Memories contain information about how you use platforms, how platforms connect together, your preferences, your business context etc  
  - (link to [Memories (/actionist/agent-memory)](#memories-\(/actionist/agent-memory\))  
- History  
  - Every action the Agent makes needs to be logged in the history.  
  - This is so that you can track the usage  
  - But also so that the Agent knows what it has done across multiple executions, using the history as context for future decisions  
  - Link to [History (/actionist/agent-history)](#history-\(/actionist/agent-history\))

- Calendar / Schedule / Time  
  - Workflows can be scheduled to run via a calendar(see [Agent Calendar (/actionist/agent-calendar-schedules)](#agent-calendar-\(/actionist/agent-calendar-schedules\))  
  - They can also be scheduled to run for a certain amount of time  
- Tools  
  - Link to [Tool Usage (/actionist/agent-tool-usage)](#tool-usage-\(/actionist/agent-tool-usage\))  
  - Agent can use tools, call functions, run code and initiate MCPs

Agent chat

- When an agent has an active session, they will be able to speak to you via the active chat.  
- You can respond to any questions, provide further information / instructions, or query the agent's progress. You can also pause and stop the workflow at any time.

Action Log

- Within the chat, you can see all of the Actions that the Agent has taken, along with context around their decisions.  
- Each of these actions is 1 execution of the Action Loop ([Token Utility ($LAM) (tokenomics/token-utility)](#token-utility-\($lam\)-\(tokenomics/token-utility\))

Video playback

- When the agent finishes its workflow, the session ends and a video is saved of the recording.  
- If using the Actionist Desktop application, this is saved locally.  
- If using the Cloud VPC ([Cloud VPC (/actionist/cloud-vpc)](#cloud-vpc-\(/actionist/cloud-vpc\))) then you can watch it from the [Actionmodel.com](http://Actionmodel.com) or Actionist.ai Dashboard.

Recording workflows

- Manually  
  - You can use the workflow editor to create workflows  
  - The editor gives you access to a visual editor, with nodes to create branches, IF conditions, loops, merges and many more  
- Recording your screen  
  - For quick and simple workflows, you can record your screen and show the AI what you want to do.  
  - When you start recording, a popup will appear that shows: Recording time, stop recording, and 3 options:  
    - Ask Human: highlight the screen to tell the AI that it needs to ask a human for confirmation about something specific on the screen  
    - Rule: highlight the screen to tell the AI it needs to take specific notice about something on the screen  
    - Variable: highlight the screen to define an important variable to the flow

Marketplace \- Workflows and Agents

- Instead of creating your own workflows, you can also access them from our marketplace  
- Learn more here: [Marketplace Overview (/marketplace/marketplace-overview)](#marketplace-overview-\(/marketplace/marketplace-overview\))







## Cloud VPC (/actionist/cloud-vpc) {#cloud-vpc-(/actionist/cloud-vpc)}

- The Actionist Desktop Application takes control the computers mouse and keyboard  
- this means that you cannot use your computer at the same time  
- To get the maximum usage out of Actionist Agents, you will also need to leave your computer running 24/7 (whilst you don't even use it yourself\!)

Actionist Cloud (VPC)

- Business and Enterprise customers can subscribe to Actionist Cloud  
- They choose a Mac or Windows machine  
- The Actionist Agent will operate this environment  
- The Actionist Agent can send you updates and ask questions / confirmation via several channels (whatsapp / Telegram)  
- The user can stream into the VPC at any time to take control or interact with the Agent

IMAGE OF ACTIONNIST DASHBOARD

Subscription Revenue

- For simplicity, B2B and Enterprise customers will purchase a monthly subscription in FIAT (£$€)  
- This purchases usage allocation of the Actionist Agent  
- This revenue is used to purchase $LAM to be consumed as fuel within the Action Loop  
- See [Token Utility ($LAM) (tokenomics/token-utility)](#token-utility-\($lam\)-\(tokenomics/token-utility\))  
- Web3 users can also connect their wallet to pay in $LAM tokens directly for a slight discount







## Actionist Browser Extension {#actionist-browser-extension}

FUTURE (DO NOT DO THIS SECTION)









## Agent Calendar (/actionist/agent-calendar-schedules) {#agent-calendar-(/actionist/agent-calendar-schedules)}

- Just like your staff that have calendars and schedules  
- Your Agents also have calendars and schedules for their workflow  
- The difference is that these agents run 24/7

IMAGES OF CALENDAR PAGES

- Daily / Weekly / Monthly view  
- List view (schedules)  
- History (PRevious executions)  
  - Opening the chat execution shows you everything that happened, along with a video playback of the entire session  
  - You can continue a session






## Memories (/actionist/agent-memory) {#memories-(/actionist/agent-memory)}

Memory sections:

- Platform preferences  
- Platform functionality  
- Relationships between platforms  
- How you like things done  
- Context about you, the agents role or the business  
- Processes, Policies and procedures

Runtime:

- Agent will automatically grab and inject memories relevant to the current execution or Action to improve the accuracy or quality of the Agent results.

Adding memories:

- You can add to memories manually  
- Background onboarding will also automatically populate memories  
- Actionist will update the Memories as it is running (executions)

## History (/actionist/agent-history) {#history-(/actionist/agent-history)}

History is everything that the Agent has done, all actions, all executions

You can view the history of an execution by opening it and viewing the action log or watching the video.

There is also a history of context, actions, memories across all platforms and executions. 

Runtime: The Agent will automatically inject all relevant history into the execution context or Action Loop. This is extremely important to ensure accuracy and prevent repetition of tasks.

For example

- Execution A: Agent is messaging your contacts in LinkedIn  
  - This is saved to the history (Platform \-\> Person, Message)  
- Execution B (months later): Agent is sending an email to someone  
  - History automatically matches the previous execution, attaching the history from Execution A into the Agent running Execution B.






## Tool Usage (/actionist/agent-tool-usage) {#tool-usage-(/actionist/agent-tool-usage)}

- (Private Beta)  
- The Agents will also be able to call external tools as part of the workflow.  
  - MCP  
  - Function calling  
  - APIs






## Triggers (/actionist/triggers) {#triggers-(/actionist/triggers)}

(Private beta)

- Connect various apps as triggers (e.g. Gmail \-\> email received)  
  - Based on the email, trigger a workflow to execute  
  - Give examples







======================================
======================================
======================================








# Marketplace (/marketplace) {#marketplace-(/marketplace)}

## Marketplace Overview (/marketplace/marketplace-overview) {#marketplace-overview-(/marketplace/marketplace-overview)}

The main goal of the marketplace is to make onboarding very easy for customers.   
Whilst users can create their own workflows or enable background onboarding, another simple way is to browse the marketplace and attach workflows to their Agents.

Within the Action Model and Actionist will exist an ecosystem filled with thousands of workflows covering all major applications, websites and platforms. These will mainly be created by our community members, partners and verified creators.

You are incentivised to publish workflows by receiving a portion of the revenue generated from each Action Loop 

- Each time a workflow is executed, there is $LAM being consumed as fuel Read [Token Utility ($LAM) (tokenomics/token-utility)](#token-utility-\($lam\)-\(tokenomics/token-utility\))   
- A portion of the $LAM Fuel consumed is distributed to the creator of the workflow: read [Revenue Generation (/marketplace/revenue-generation)](#revenue-generation-\(/marketplace/revenue-generation\))

This will result in a rich ecosystem of not only the best workflows, but also an entire economy consisting of Agencies, Consultancies, Influencers teaching how to make Actionist Workflows/Agents, Selling courses, Selling workflows etc.

Functionality:

Marketplace home page  
URL: [train.actionmodel.com/marketplace](http://train.actionmodel.com/marketplace) 

- Marketplace is filled with platforms (apps, websites and sub-domains)  
- Each app has workflows connected to it that you can browse  
- SCREENSHOT OF MARKETPLACE  
- You will have easy visibility of the bounty on available for each App (See [Marketplace Bounties (/marketplace/marketplace-bounties)](#marketplace-bounties-\(/marketplace/marketplace-bounties\))  
- You can also filter by tags and/or search Apps or Workflows directly from the homepage

App Workflows

- You can view the published workflows by opening the App  
- These workflows can be easily added to your Agents and scheduled in the calendar (see [Agent Calendar (/actionist/agent-calendar-schedules)](#agent-calendar-\(/actionist/agent-calendar-schedules\))  
- \*\*Screenshot of the Workflows page of a specific app

Workflow Config

- Once you click on a workflow, you can see the configuration  
- Learn more about workflow config here: [Agents & Workflows (/actionist/agents-and-workflows)](#agents-&-workflows-\(/actionist/agents-and-workflows\))  
- There are two types of workflows:  
  - Basic \- this is a linear workflow with a simple set of steps  
  - Complex \- these are workflows created with our workflow editor. These workflows have Chains, Loops, IF conditions and many more options.  
- You can also see the additional config of the workflows  
  - Variables, Rules, Ask Human, Success Criteria

Creator Profiles

- Your Creator Profile is public and visible to the community and businesses.  
- Within here, you can advertise your own services, website or socials  
- This is designed to provide consultancy services to businesses, providing bespoke workflows or management  
- \*\*Screenshot of the Creator Profile  
- Link to [Featured Workflows and Reputation (/marketplace/marketplace-reputation-and-featured-workflows)](#featured-workflows-and-reputation-\(/marketplace/marketplace-reputation-and-featured-workflows\))







## Marketplace Bounties (/marketplace/marketplace-bounties) {#marketplace-bounties-(/marketplace/marketplace-bounties)}

- Page: [train.actionmodel.com/bounties](http://train.actionmodel.com/bounties)  
- Websites, Apps and Platforms have different inherent values.  
- Action Model has ranked thousands of Apps, Websites and Platforms based on their inherent value to our customers (B2C, B2B and Enterprise)  
- The ultimate goal of community contribution is:  
  - 1\. Training the LAM (See [Training the LAM (/the-large-action-model-lam/training-the-large-action-model)](#training-the-lam-\(/the-large-action-model-lam/training-the-large-action-model\))  
  - 2\. Creating Workflows (See [Agents & Workflows (/actionist/agents-and-workflows)](#agents-&-workflows-\(/actionist/agents-and-workflows\))  
- Therefore, the more commercially valuable the Website/App is for a customer, the higher the bounty will be placed for the contributor.

Bounty variables

- Bounties changes based on certain factors:  
  - Commercial value of the App/Website to our customers (the more valuable the automation is to a business, the higher the bounty)  
  - The number of users training on the App/Website (more users \= more training/workflows \= less bounty)  
  - If there are any new updates or features to the app/website \= increased bounty to increase coverage of training/workflows on the new functionality, UI etc.

Bounty example:  
Lets compare these two platforms

- [Facebook.com](http://Facebook.com) \-\> Bounty will be around 0%-25% above base-line.   
  - This is because 1\. [Facebook.com](http://Facebook.com) isn’t very commercially valuable to a business, 2\. There is a very large number of people browsing [facebook.com](http://facebook.com), meaning that a lot of training data is being collected, reducing the bounty  
- [business.facebook.com](http://business.facebook.com) \-\> Bounty is around 700% above base-line  
  - This is because 1\. [business.facebook.com](http://business.facebook.com) is a B2B tool. Businesses have full-time staff managing this tool (or they hire agencies/consultants to do it), this makes it very commercially valuable to automate, since the Agents will save the customer money. 2\. There are very few people (compared to [facebook.com](http://facebook.com)) using [business.facebook.com](http://business.facebook.com), this results in a higher bounty to incentivise more users.

For each of the platforms, you can see the workflows that have a high request rate or commercial value.

- Screenshot of [facebook.com](http://facebook.com) bounties page  
- Screenshot of business.[facebook.com](http://facebook.com) bounties page

You can review your earnings from Bounties via the Training History Tab ([train.actionmodel.com/training-history](http://train.actionmodel.com/training-history)), the Marketplace Tab ([train.actionmodel.com/marketplace](http://train.actionmodel.com/marketplace)) or the main Dashboard page  
\*\*\*SCREENSHOTS OF EACH PAGE






## Revenue Generation (/marketplace/revenue-generation) {#revenue-generation-(/marketplace/revenue-generation)}

In addition to earning $LAM for Training the Large Action Model ([Training the LAM (/the-large-action-model-lam/training-the-large-action-model)](#training-the-lam-\(/the-large-action-model-lam/training-the-large-action-model\)) you can also earn $LAM and generate revenue by publishing workflows that Actionist customers can use (see [Marketplace (/marketplace)](#marketplace-\(/marketplace\))

You are incentivised to publish workflows by receiving a portion of the revenue generated from each Action Loop 

- Each time a workflow is executed, there is $LAM being consumed as fuel Read [Token Utility ($LAM) (tokenomics/token-utility)](#token-utility-\($lam\)-\(tokenomics/token-utility\))   
- A portion of the $LAM Fuel consumed is distributed to the creator of the workflow: read [Revenue Generation (/marketplace/revenue-generation)](#revenue-generation-\(/marketplace/revenue-generation\))

Within our ecosystem, we envisage:

- Solopreneurs to create and publish workflows to make money  
- Influencers to create content around workflows or agents, and sell courses  
- Agencies specialised in creating workflows for businesses  
- Consultancies focusing on Enterprise enablement, delivery and management

\*\*EXPAND ON THESE

The earliest users in our community of creators (as long as they are contributing well-prepared workflows that provide high customer utility) will be rewarded the most. These creators will become featured, their workflows pinned to apps, and their profiles recommended as Verified creators.

A breakdown of the distributions and tokenomics for marketplace creators can be found here: [Marketplace Distributions (tokenomics/marketplace-distributions)](#marketplace-distributions-\(tokenomics/marketplace-distributions\))





## Featured Workflows and Reputation (/marketplace/marketplace-reputation-and-featured-workflows) {#featured-workflows-and-reputation-(/marketplace/marketplace-reputation-and-featured-workflows)}


We promote the workflows or accounts of the early adopters and contributors. Workflows will be pinned to Apps (so the first to create workflows for platforms will have the most advantageous position and generate the most money). 

Being the early contributors is a huge benefit, but also creating quality workflows that have high utility and consistent usage rates will increase your overall platform reputation (scoring system) and your user profile account.

User Verification: These are the type of profiles:

- Community (General members of the community)  
- Verified (Power users with high reputation or usage)  
- Partner (The Administrator of an App)

In the future, we will introduce tiers specifically to segment power users, consultancies and agencies \- we will also showcase a partners page to promote these groups and their specialities within our platform.

Workflow scoring

- Find mechanism to score creators and workflow publishers  
- Creators will have a reputation score  
- Based on: workflows used, tokens consumed  
- Token efficiency score  
  - This is a moving average ratio calculated based on the success of a workflow and the number of tokens consumed by a workflow.   
  - The higher the count of successful workflows, compared to the number of tokens will create a score

Creator Profiles

- Your Creator Profile is public and visible to the community and businesses.  
- Within here, you can advertise your own services, website or socials  
- This is designed to provide consultancy services to businesses, providing bespoke workflows or management  
- \*\*Screenshot of the Creator Profile










======================================
======================================
======================================








# The Large Action Model (LAM) (/the-large-action-model) {#the-large-action-model-(lam)-(/the-large-action-model)}

## Training the LAM (/the-large-action-model-lam/training-the-large-action-model) {#training-the-lam-(/the-large-action-model-lam/training-the-large-action-model)}

First, we need to discuss the differences between a LLM and an LAM.

- LLM is great at predicting language \- hence it is a Large Language Model  
- LAMs are great at outputting Actions \- based on the environment and context, they can accurately predict the next Action (along with how to execute it \- e.g. “Click Mouse Coordinates 273,837”)

LAMs are significantly more tedious to train, mainly due to the complex training data required (which doesn’t exist naturally on the internet). LAMs are in their infancy, comparable to GPT1 level quality and reliability (across the board). This is mainly due to the quality of training data and collection techniques, making it hard to teach an AI how to use various websites, apps and platforms.

Training Data Required

- LLM (Large Language Model \- Chatbot)  
  - training data is relatively easy to source, it exists naturally on the internet to be downloaded/scraped  
  - Books, Articles, Journals, Blogs, Social Media, Scientific Papers etc..  
  - These are straightforward to scrape from the internet, and now you can also download pre-prepared LLM Training data  
    - [https://github.com/Zjh-819/LLMDataHub](https://github.com/Zjh-819/LLMDataHub)  
    - [https://huggingface.co/collections/sugatoray/llm-training-datasets-65dbe4ab2b0037ec198b09ab](https://huggingface.co/collections/sugatoray/llm-training-datasets-65dbe4ab2b0037ec198b09ab)  
  - LLM Training data can also be created synthetically now by other AI models.  
    - https://www.confident-ai.com/blog/the-definitive-guide-to-synthetic-data-generation-using-llms 

- LAM (Large Action Model \- Computer Agent)  
  - To perfectly train a LAM, you need to MAP every functionality and journey in a specific website/platform, and also the journeys between platforms.  
  - A journey, path or functionality in a platform is called an Action Branch.  
    - This consists of: Intent \-\> Action Sequence \-\> Goal  
    - IMAGE OF ACTION BRANCH

      

  - For example, to train the AI how to make a reservation on [booking.com](http://booking.com), you need to collect interaction data for EACH of the following Actions  
    - Open [booking.com](http://booking.com)  
    - Click: Search bar (Mouse Coordinates)   
    - Type: {{Variable}} (Location)  
    - Click: Date picker  
    - Click: Start date  
    - Click: End date  
    - Click: Occupancy button  
    - Click: plus button (increase to 2 people)  
    - Click: search button  
    - Wait: 5 seconds  
    - Click: Hotel Option  
    - Click: room option  
    - Etc… (CLAUDE PLEASE FINISH THIS \- format it nicely)

  - Interaction Data:  
    - For EACH of the above, you need to collect the following Interaction Data:  
      - Screenshot of the Element  
      - Screenshot of the screen (Recommended)  
      - Action Context  
      - Mouse Coordinates  
      - Device Width/Height  
      - HTML Elements  
      - DOM Elements  
      - (\*\* CLAUDE Format this nicely)  
  - The above is collected for each of the Actions.  
  - This sequence of Actions, along with the Interaction Data is what is used to effectively train a single Branch in the Action Model  
  - Training data does not exist naturally on the internet, you cannot download it from anywhere.  
  - As you can see by the detailed 

The Action Tree

- Millions of branches come together, training the LAM on every path, functionality, journey on every single application, website and platform. This data is collected by the Browser Extension (see Browser Extension Overview (/the-large-action-model-lam/browser-extension-overview)  
  - Download extension here: [https://chromewebstore.google.com/detail/action-model/lhciigpkocgkbnbjimbbiejpfijdbcag?authuser=0\&hl=en](https://chromewebstore.google.com/detail/action-model/lhciigpkocgkbnbjimbbiejpfijdbcag?authuser=0&hl=en)  
- The Action Tree is capable of identifying the users current position in the tree, and a specific branch, and predicting the next accurate Action to take.  
- This process happens as a loop (Called the Action Loop), in which the Agent will  
  - look at your environment, history, goal, context  
  - find your position in the tree  
  - Predict the next Action  
  - Execute the action  
  - Back to step 1  
- Read more about how this works in [Token Utility ($LAM) (tokenomics/token-utility)](#token-utility-\($lam\)-\(tokenomics/token-utility\))  
- To enable B2B and Enterprise customers to trust AI with full automation of their computers, you need perfect accuracy. This can only be achieved if the LAM is trained on the exact journey  
- By collecting millions of branches, not only does the LAM understand exactly how to perfect a specific task that it has been trained on, but the overall contextual understanding improves when asked to execute an untrained path or task.

IMAGE OF THE ACTION TREE

As you can see, this data required to perfectly train an LAM needs to be manually curated, hence the need for the Action Model community and the browser extension (Browser Extension Overview (/the-large-action-model-lam/browser-extension-overview)

Comparison data quality:

- Some other LAMs being developed have used desperate training data. For example, collections of minute long youtube videos / clips of people creating “How to Videos”  
- E,g, a Youtube video titled “How To Import Contacts To HubSpot CRM From A Spreadsheet”  
- The screenshots of the UI and elements the mouse clicked are extracted from the video and used to train the model.  
  - [https://www.youtube.com/watch?v=loWNs1KJSm8](https://www.youtube.com/watch?v=loWNs1KJSm8)  
- This data quality is terrible, outdated and incomplete compared to the data that Action Model collects







## Browser Extension Overview (/the-large-action-model-lam/browser-extension-overview) {#browser-extension-overview-(/the-large-action-model-lam/browser-extension-overview)}

 

- Firstly, Download the extension here:  
  - [https://chromewebstore.google.com/detail/action-model/lhciigpkocgkbnbjimbbiejpfijdbcag?authuser=0\&hl=en](https://chromewebstore.google.com/detail/action-model/lhciigpkocgkbnbjimbbiejpfijdbcag?authuser=0&hl=en)  
- Login is synced to the Dashboard ([train.actionmodel.com](http://train.actionmodel.com))  
  - If you are logged into dashboard, you will automatically be logged into the browser extension

By using the browser extension, you can train the LAM and warn tokens.

- Learn more about rewards Token Utility ($LAM) (tokenomics/token-utility)  
- You can also earn tokens in other ways How to be part of the AI Future (/the-action-model/how-to-be-part-of-the-ai-future)

Training Types  
There are two main training types that you can train the LAM with  
(read more here: Browser Extension Overview (/the-large-action-model-lam/browser-extension-overview)

- Train In Background  
  - Background training is the simplest way to earn tokens  
  - It takes 60 seconds to turn on, and then you can forget about it while you are training the LAM in the background  
  - Background mode will remain running indefinitely until you turn it off.  
  - Your training log will be split into 24 hour chunks in the dashboard  
  - There are no screenshots collected in background mode

- Train with Custom Web Agent option  
  - Custom Web Agents earn 2x more points for training  
  - This is due to the fact that it has intent (you need to start and stop the workflow) which makes it easier to train the LAM  
  - More data is also collected (e.g. screenshots, workflow context)

Training History

- In the Dashboard, you can access all of your training history  
- [train.actionmodel.com/training-history](http://train.actionmodel.com/training-history)  
- SCREENSHOT OF TRAINING HISTORY TAB

Example of Custom Training

- This workflow recorded is a [Booking.com](http://Booking.com) reservation  
- After completing a Custom Training, you can find it in the dashboard under the Training History tab  
- You can view all of the data collected and each of the Interactions in the workflow  
- Screenshot of Branch Context  
  - This is what the LAM understands of your workflow and the context behind each action that you made  
  - You can compare this to the Action Branch at each step to see.  
- \*\*SEE IF YOU CAN FIND A COMPONENT THAT PUTS ALL OF THESE IN MINI TABS:  
  - Screenshot of step1 of the Action Branch  
    - In here, the user has opened the Calendar view  
  - Screenshot 2  
    - User has clicked the 8th of July  
  - Screenshot 3  
    - User has clicked the 18th of July  
  - Screenshot 4  
    - User has clicked the Occupancy configuration button




Personal information, privacy and security

- We do not train the LAM on any personal data, and we take measures to remove personal information  
- Personal information is removed from the data collected and screenshot on your local machine.  
- They are also obfuscated from the screenshots  
- You can read more about this here Security & Privacy (/the-large-action-model-lam/security-and-privacy

Training Bounties

- You can earn additional rewards by training in the background on platforms that have higher bounty value. Learn more here:  
- Link to [Training & Marketplace Bounties](#training-&-marketplace-bounties-\(tokenomics/training-and-marketplace-bounties\))








## Security & Privacy (/the-large-action-model-lam/security-and-privacy  {#security-&-privacy-(/the-large-action-model-lam/security-and-privacy}

Custom Training Screenshots

- In custom training mode, the user starts the training, trains their workflow and then stops the training.  
- Since there is user intent, we collect screenshots for these types of trainings (this helps with the training the LAM)  
- Please note: We do not collect any screenshots from background training

- Personal information is removed from the data collected and screenshot on your local machine.  
- They are also obfuscated from the screenshots  
- You can see in this workflow, the personal information has been removed from the Reservation Confirmtion page  
- \*\*SCREENSHOT OF RESERVATION PAGE

Website Block List

- Website history  
  - [train.actionmodel.com/websites](http://train.actionmodel.com/websites)  
  - You can also see all of the websites that you have trained on here  
  - \*\*SCREENSHOT OF WEBSITES TAB  
- Blocked sites:  
  - We block training by default on a large number of websites  
  - You can view this list and add any websites to it  
  - \*\*SCREENSHOT OF

Deleting data

- At any time, you can delete your data or trainings from our platform  
- \*\*Screenshot of the deletion buttons  
- You can do this from the Training History tab, either the entire training or individual Actions in the trainings.

CASA Certification

- We are ESOF AppSec ADA CASA – Enterprise – Tier 3 certified  
- \*\*Explain what this is

PEN Tested

- The Action Model Foundation has undertaken extensive Penetration Testing prior to launch by external firms.  
- Explain what they do in normal pen tests









======================================
======================================
======================================










# Tokenomics (/tokenomics) {#tokenomics-(/tokenomics)}

Calculations: [https://chatgpt.com/g/g-67c5583d21d8819180973a8633211e17-large-action-model/c/68b3ff51-f8c4-8331-ac9b-2f3f7f6929ac](https://chatgpt.com/g/g-67c5583d21d8819180973a8633211e17-large-action-model/c/68b3ff51-f8c4-8331-ac9b-2f3f7f6929ac) 


## Token Utility ($LAM) (tokenomics/token-utility) {#token-utility-($lam)-(tokenomics/token-utility)}

**$LAM Ecosystem**

- **Action Fuel** – Every agent click, type, scroll, upload, or form submit consumes $LAM as Fuel.  
- **DAO** \- Decentralised Autonomous Organization (Action Model is the Uprising (/the-action-model/action-model-is-the-uprising)  
- **Marketplace** \- Earn from your Workflows and Agents(Marketplace Overview (/marketplace/marketplace-overview)  
- **Train the LAM** \- contributors who help train the Large Action Model (Training the LAM (/the-large-action-model-lam/training-the-large-action-model)  
- **Action credits** – Partners and devs preload $LAM to fund fleets of agents.  
- **Referrals, Affiliates and Quests:** Referrals, Affiliates & Quests (tokenomics/referrals-and-affiliates)

**$LAM Token Overview**

- **$LAM is Action Fuel.** Every GUI action executed by a LAM agent consumes $LAM.  
- **Price‑in‑USD per action is fixed by LAM version** (e.g., **LAM‑1 \= $0.01/action**), while the **number of tokens per action floats with the token price**.  
- **Each consumed action distributes tokens**: **34% Burn**, **33% Marketplace Distribution**, **33% Action Model Foundation** (foundation ops, rewards, R\&D).  
- **B2B \+ Partners create continuous buy pressure.** Subscriptions and API usage require $LAM purchases to fund actions. Paying subscriptions directly in $LAM grants a **10% discount**.  
- **Deflationary dynamics.** Because a share of every action is burned, higher usage permanently reduces supply; the rest recirculates to creators/foundation to grow the ecosystem.

**The Action Loop**

(how tokens are consumed)

**Loop (repeats until the workflow is done):**

1. **Context in:** History, goal, memories, DOM/HTML, element embeddings, and a live screenshot.  
2. **Decide:** LAM queries the **Action Tree** and policy to pick the **Next Action**.  
3. **Act:** The precise GUI action is executed (click/keystroke/drag/etc.).  
4. **Consume Fuel:** This single action consumes $LAM according to the active LAM version’s price schedule.  
5. **Repeat** until Goal is reached or allotted time is finished.

**Every iteration** of this loop is a **billable action**.

**Pricing model (versioned “price per action”)**

* Let **pvp\_vpv​** be the **USD price per action for model version vvv** (e.g., **LAM‑1** has p1=$0.10p\_1 \= \\$0.10p1​=$0.10 / action).

* Let **PtP\_tPt​** be the **market price of $LAM in USD** at time ttt.

* **Tokens required per action** for version vvv at time ttt is:

τv,t=pvPt\\boxed{\\tau\_{v,t} \= \\frac{p\_v}{P\_t}}τv,t​=Pt​pv​​​

* **Fractional tokens** are supported to meter actions precisely.

**Examples (LAM‑1):**

* If Pt=$0.01P\_t \= \\$0.01Pt​=$0.01, then τ1,t=0.10/0.01=10 tokens/action\\tau\_{1,t} \= 0.10 / 0.01 \= 10\\ \\text{tokens/action}τ1,t​=0.10/0.01=10 tokens/action.

* If Pt=$0.10P\_t \= \\$0.10Pt​=$0.10, then τ1,t=1 token/action\\tau\_{1,t} \= 1\\ \\text{token/action}τ1,t​=1 token/action.

* If Pt=$1.00P\_t \= \\$1.00Pt​=$1.00, then τ1,t=0.1 token/action\\tau\_{1,t} \= 0.1\\ \\text{token/action}τ1,t​=0.1 token/action.

**USD cost per action is stable** for developers; **tokens per action adjusts automatically** to market price.

**Token Fuel distribution (per action)**

Let the distribution shares be:

* **Burn share** β=0.34\\beta \= 0.34β=0.34

* **Marketplace creator share** μ=0.33\\mu \= 0.33μ=0.33

* **Foundation share** ϕ=0.33\\phi \= 0.33ϕ=0.33

For one action that consumes τ\\tauτ tokens:

Burned tokens/action=β⋅τCreator tokens/action=μ⋅τ(if a Marketplace workflow was used)Foundation tokens/action=ϕ⋅τ\\begin{aligned} \\text{Burned tokens/action} &= \\beta \\cdot \\tau \\\\ \\text{Creator tokens/action} &= \\mu \\cdot \\tau \\quad \\text{(if a Marketplace workflow was used)} \\\\ \\text{Foundation tokens/action} &= \\phi \\cdot \\tau \\end{aligned}Burned tokens/actionCreator tokens/actionFoundation tokens/action​=β⋅τ=μ⋅τ(if a Marketplace workflow was used)=ϕ⋅τ​

**USD equivalents per action (version with pvp\_vpv​):**

USD burned/action=β⋅pvUSD to creator/action=μ⋅pvUSD to foundation/action=ϕ⋅pv\\boxed{\\text{USD burned/action} \= \\beta \\cdot p\_v} \\qquad \\boxed{\\text{USD to creator/action} \= \\mu \\cdot p\_v} \\qquad \\boxed{\\text{USD to foundation/action} \= \\phi \\cdot p\_v}USD burned/action=β⋅pv​​USD to creator/action=μ⋅pv​​USD to foundation/action=ϕ⋅pv​​

For **LAM‑1** (p1=$0.10p\_1 \= \\$0.10p1​=$0.10): **$0.034** is burned, **$0.033** goes to the creator (if used), and **$0.033** to the foundation **per action**, independent of token price.

**The buyback loop (why usage creates demand)**

* **B2B subscriptions** (e.g., $1k–$2k per agent/month) and **API partners** include **usage allowances measured in actions**.

* To deliver those actions, **operators must acquire $LAM** (buy on the market or hold inventory).

* When actions run, tokens flow through the **Fuel distribution** above (with **34% burned**).

**Paying subscriptions in $LAM (10% discount)**

* Paying a $1,000 subscription in $LAM yields a **10% discount**: you spend tokens equivalent to **$900** at the time of payment.

* Those tokens may be escrowed and released into the **Fuel distribution** as actions are consumed (implementation detail—DAO parameter).

**Tokens needed to pay a subscription SSS in USD with a discount ddd:**

Tokens=S(1−d)Pt\\boxed{ \\text{Tokens} \= \\frac{S(1-d)}{P\_t} }Tokens=Pt​S(1−d)​​

**Formal tokenomics model**

**Per‑action accounting (LAM‑vvv)**

* **Tokens per action:** τv,t=pvPt\\tau\_{v,t} \= \\frac{p\_v}{P\_t}τv,t​=Pt​pv​​

* **Burn:** Bact=βτv,tB\_{\\text{act}} \= \\beta \\tau\_{v,t}Bact​=βτv,t​

* **Creator:** Mact=μτv,t⋅1marketplaceM\_{\\text{act}} \= \\mu \\tau\_{v,t} \\cdot \\mathbb{1}\_{\\text{marketplace}}Mact​=μτv,t​⋅1marketplace​

* **Foundation:** Fact=ϕτv,tF\_{\\text{act}} \= \\phi \\tau\_{v,t}Fact​=ϕτv,t​

**Network‑level, period ttt (e.g., monthly)**

Let AtA\_tAt​ be actions executed in ttt. Then:

Tokens neededDt=τv,t⋅AtBurned tokensBt=β⋅DtCreator tokensMt=μ⋅Dt⋅Pr⁡(marketplace use)Foundation tokensFt=ϕ⋅DtUSD spent on actionsUt=pv⋅At(price‑invariant)\\begin{aligned} \\text{Tokens needed} \\quad \&D\_t \= \\tau\_{v,t} \\cdot A\_t \\\\ \\text{Burned tokens} \\quad \&B\_t \= \\beta \\cdot D\_t \\\\ \\text{Creator tokens} \\quad \&M\_t \= \\mu \\cdot D\_t \\cdot \\Pr(\\text{marketplace use}) \\\\ \\text{Foundation tokens} \\quad \&F\_t \= \\phi \\cdot D\_t \\\\ \\text{USD spent on actions} \\quad \&U\_t \= p\_v \\cdot A\_t \\quad (\\text{price‑invariant}) \\end{aligned}Tokens neededBurned tokensCreator tokensFoundation tokensUSD spent on actions​Dt​=τv,t​⋅At​Bt​=β⋅Dt​Mt​=μ⋅Dt​⋅Pr(marketplace use)Ft​=ϕ⋅Dt​Ut​=pv​⋅At​(price‑invariant)​

**Supply dynamics**

Let StS\_tSt​ be circulating supply at start of ttt. Let EtE\_tEt​ be new emissions (training rewards, grants) approved by DAO.

St+1=St+Et−Bt\\boxed{S\_{t+1} \= S\_t \+ E\_t \- B\_t}St+1​=St​+Et​−Bt​​

* **Deflationary condition:** Bt\>EtB\_t \> E\_tBt​\>Et​.

* **Neutral:** Bt=EtB\_t \= E\_tBt​=Et​.

* **Inflationary:** Bt\<EtB\_t \< E\_tBt​\<Et​.

**Break‑even emissions** (deflation‑neutral):

Et⋆=β⋅τv,t⋅At\\boxed{E^{\\star}\_t \= \\beta \\cdot \\tau\_{v,t} \\cdot A\_t}Et⋆​=β⋅τv,t​⋅At​​

“Half‑life” under constant burn and no emissions (illustrative)

If actions are steady and Et=0E\_t=0Et​=0, supply declines linearly. Time to reduce supply by half:

T12=S02⋅Bt=S02⋅β⋅τv,t⋅At\\boxed{T\_{\\frac{1}{2}} \= \\frac{S\_0}{2 \\cdot B\_t}} \= \\frac{S\_0}{2 \\cdot \\beta \\cdot \\tau\_{v,t} \\cdot A\_t}T21​​=2⋅Bt​S0​​​=2⋅β⋅τv,t​⋅At​S0​​

**$LAM Token Burn / Deflationary model**  
A proportion of $LAM tokens consumed as Fuel via this mechanism will be burnt, reducing the overall token supply and float, providing further token holder value. 

**$LAM Token Marketplace Distribution**  
If the customer has used a workflow from the Action Model Marketplace, then a proportion of the consumed workflows will be given to the community member that created that workflow  
Read more: Marketplace Overview (/marketplace/marketplace-overview)

**$LAM Token Training Distribution**  
In the future, we may also distribute a proportion of the $LAM tokens consumed as fuel will be distributed to the LAM Trainers who provided Branches / Trees to those relevant workflows.

E.g, if 1000 users trained the LAM by creating an EC2 instance in AWS \- then anytime Action Fuel is consumed with relevant workflows to this, the Training Distribution portion of the fuel will be distributed to the trainers relevant to the workflow.

**Action Model API (Developers)**  
Third Party developers wanting to build software using the Large Action Model will need to connect to the LAM API. 

This is akin to developers connecting to the OpenAI API.

OpenAI API

- Developer sends prompt to API \- “Write me a blog post about Coffee” (7 input tokens)  
- API responds with an output \- “The best coffee in the world is …” (1000 output tokens)  
- OpenAI Pricing (4.1) is $2/1m input tokens \+ $8/1m output tokens  
- Users pay for the combined input \+ output tokens in USD

Action Model API

- Developer sends request to API (User Environment):  
  - User Goal (“Configure me an AWS instance”) (and workflow steps)  
  - User History (What actions have happened previously, including their state)  
  - Screenshot of screen (Helps AI understand its current position)  
  - HTML / Source code (entire web page)  
  - DOM elements (compressed form of the interactive elements)  
  - System prompt \+ Agent Config \+ Context (optional information to increase relevance accuracy)  
- API responds with an Action output \- “\<Click Interaction\>{Mouse Coordinates}” **(This is the next action)**

Unlike LLMs that are trained specifically to output text, the LAM is trained to output the next ACTION. It is a specific sequence of actions that combine together to reach an end goal.

**Long Term Economic Benefits**

* **Price‑stable UX for customers.** They think in actions and USD; our tokenization handles volatility.  
* **Automatic market clearing.** As $LAM rises, fewer tokens/action are required; as it falls, more tokens are required—demand (in tokens) is counter‑cyclical while USD flow is stable.  
* **Per‑action burn builds long‑term scarcity.** Usage permanently removes supply; creators and the foundation recycle the remainder into growth.  
* **Creators are aligned.** They earn **cash‑equivalent per action** regardless of $LAM price—rewarding utility, not speculation.






## Point Tiers and Epochs (tokenomics/training-to-earn-tokens {#point-tiers-and-epochs-(tokenomics/training-to-earn-tokens}

**Points Tiers and Epochs**

- To incentivise early contributors and long term community members  
- The more dedicated you are to the Action Model, the more you earn, increasing your stake in the future of AI

**Points Tier Bonuses (Badge Tiers)**

| Tier | Points Range | Badge Bonus |
| :---- | :---- | :---- |
| Seed | 0 – 9,999 | \+0% |
| Root | 10K – 49,999 | \+5%  (or 1.05x) |
| Sprout | 50K – 249,999 | \+10%  (or  1.1x) |
| Leaf | 250K – 999,999 | \+15%  (or  1.15x) |
| Branch | 1M – 4,999,999 | \+20% (or 1.20x) |
| Tree | 5M – 24,999,999 | \+30%  (or 1.30x) |
| Forest | 25M – 99,999,999 | \+40%  (or 1.40x) |
| Evergreen | 100M+ | \+50%   (or 1.50x) |

**Epochs**

| Epoch | Period | Bonus |
| :---- | :---- | :---- |
| Founding | Founders/KOLs | 5x |
| Epoch 1 | Month 1 | 2x |
| Epoch 2 | Month 2 | 1.9x |
| Epoch 3 | Month 3 | 1.8x |
| Epoch 4 | Month 4 | 1.7x |
| Epoch 5 | Month 5 | 1.6x |
| Epoch 6 | Month 6 | 1.5x |
| Epoch 7 | Month 7 | 1.4x |
| Epoch 8 | Month 8 | 1.3x |
| Epoch 9 | Month 9 | 1.25x |
| Epoch 10 | Month 10 | 1.2x |
| Epoch 11 | Month 11 | 1.1x |
| Epoch 12+ | Month 12+ | 1x |

**Example Calculations**

**Scenario 1: Founding member, Scenario recording, Gold website**

* Actions: 1,000  
* Bonuses: \+100% (scenario) \+100% (founding epoch) \+100% (gold bounty) \+0% (seed badge)  
* Total: 1,000 × (1 \+ 1.0 \+ 1.0 \+ 1.0 \+ 0\) \= 1,000 × 4 \= **4,000 points**

**Scenario 2: Power user at Tree tier, Epoch 3**

* Actions: 2,000  
* Bonuses: \+100% (scenario) \+30% (epoch 3\) \+70% (silver bounty) \+30% (tree badge)  
* Total: 2,000 × (1 \+ 1.0 \+ 0.3 \+ 0.7 \+ 0.3) \= 2,000 × 3.3 \= **6,600 points**

**Scenario 3: New user, Background recording, Epoch 13 (no epoch bonus)**

* Actions: 500  
* Bonuses: \+0% (background) \+0% (no epoch) \+30% (bronze bounty) \+5% (sprout badge)  
* Total: 500 × (1 \+ 0 \+ 0 \+ 0.3 \+ 0.05) \= 500 × 1.35 \= **675 points**





## Marketplace Distributions (tokenomics/marketplace-distributions) {#marketplace-distributions-(tokenomics/marketplace-distributions)}

You are incentivised to publish workflows by receiving a portion of the revenue generated from each Action Loop 

- Each time a workflow is executed, there is $LAM being consumed as fuel Read [Token Utility ($LAM) (tokenomics/token-utility)](#token-utility-\($lam\)-\(tokenomics/token-utility\))   
- A portion of the $LAM Fuel consumed is distributed to the creator of the workflow: read [Revenue Generation (/marketplace/revenue-generation)](#revenue-generation-\(/marketplace/revenue-generation\))

This will result in a rich ecosystem of not only the best workflows, but also an entire economy consisting of Agencies, Consultancies, Influencers teaching how to make Actionist Workflows/Agents, Selling courses, Selling workflows etc.

**Marketplace economics (why creators win)**

If a Marketplace workflow is used in a run of X actions:

Creator USD per run=μ⋅pv⋅k\\text{Creator USD per run} \= \\mu \\cdot p\_v \\cdot kCreator USD per run=μ⋅pv​⋅k

For LAM‑1 (p1=$0.10p\_1=\\$0.10p1​=$0.10, μ=0.33\\mu=0.33μ=0.33):

Creator USD per run=$0.033×k\\boxed{\\text{Creator USD per run} \= \\$0.033 \\times k}Creator USD per run=$0.033×k​

* **1,000 runs/month, each 100 actions:** Creator earns 0.033×100×1,000=$3,3000.033 \\times 100 \\times 1{,}000 \= \\$3{,}3000.033×100×1,000=$3,300 / month.

* This **USD earning per action is invariant** to token price.  
* As tokens get burnt/locked 

This is a strong incentive to publish high‑quality reusable workflows.







## Training & Marketplace Bounties (tokenomics/training-and-marketplace-bounties) {#training-&-marketplace-bounties-(tokenomics/training-and-marketplace-bounties)}

**Training Types**  
There are two main training types that you can train the LAM with  
(read more here: Browser Extension Overview (/the-large-action-model-lam/browser-extension-overview)

- Train In Background  
  - Background training is the simplest way to earn tokens  
  - It takes 60 seconds to turn on, and then you can forget about it while you are training the LAM in the background  
  - Background mode will remain running indefinitely until you turn it off.  
  - Your training log will be split into 24 hour chunks in the dashboard  
  - There are no screenshots collected in background mode

- Train with Custom Web Agent option  
  - Custom Web Agents earn 2x more points for training  
  - This is due to the fact that it has intent (you need to start and stop the workflow) which makes it easier to train the LAM  
  - More data is also collected (e.g. screenshots, workflow context)

| Type | Bonus |
| :---- | :---- |
| Background Training | \+0% (Baseline) |
| Custom Agent/Scenario | \+100% |

**Bounties**  
Bounties are designed to route community training traffic to high-value targets.  
Bounties changes based on certain factors:

- Commercial value of the App/Website to our customers (the more valuable the automation is to a business, the higher the bounty)  
- The number of users training on the App/Website (more users \= more training/workflows \= less bounty)  
- If there are any new updates or features to the app/website \= increased bounty to increase coverage of training/workflows on the new functionality, UI etc.

You can read more about bounties here: [Marketplace Bounties (/marketplace/marketplace-bounties)](#marketplace-bounties-\(/marketplace/marketplace-bounties\))

SCREENSHOTS OF BOUNTIES PLATFORM

## Referrals, Affiliates & Quests (tokenomics/referrals-and-affiliates) {#referrals,-affiliates-&-quests-(tokenomics/referrals-and-affiliates)}

- Why spread the message  
- Why refer people  
- Action Model is the Resistance, uprising, movement  
- More people \= faster growth

How community size effects our growth

1. More people to train the LAM  
   1. With enough users, we will be able to collect enough rich training data to create a world-leading Large Action Model  
2. More people to create workflows  
   1. Wider array and breadth of workflows, covering all B2B and Enterprise requirements  
3. More Distribution of the Actionist  
   1. Finally, we need you to tell businesses to use the Actionist\!  
   2. The revenue generated from the Actionist is used to buy-back and burn tokens  
   3. Read more here: Token Utility ($LAM) (tokenomics/token-utility)

**Affiliate Reward Tiers & Referral Bonuses**

To encourage community growth, you can earn extra points by referring others. There are two ways you benefit:  
**1\. Affiliate Earnings – Ongoing Percentage of Referees' Points**

As your number of successful referrals grows, so does the percentage of their earned points you receive — without affecting their points total.

| Tier | Number of Referrals | Affiliate Bonus (% of Referees' Points) |
| :---- | :---- | :---- |
| Tier 1 | 0–5 | 5% |
| Tier 2 | 6–20 | 10% |
| Tier 3 | 21–100 | 15% |
| Tier 4 | 101–999 | 20% |
| Tier 5 | 1000+ | 25% |

**Example calculation:**  
Someone you referred earns 10,000 points in a session. If you're in Tier 3 (15%), you'll receive:  
ROUND(10,000 \* 15 / 100\) \= 1,500 bonus points

**2\. One-Time Referral Bonuses**

You'll also receive fixed bonus points at two key milestones for each person you refer:

| Tier | Initial Bonus (on sign-up) | Qualified Bonus (after 10min recording) | Total Bonus |
| :---- | :---- | :---- | :---- |

| Tier | Initial Bonus (on sign-up) | Qualified Bonus (after 10min recording) | Total Bonus |
| :---- | :---- | :---- | :---- |
| Tier 1 | 1000 points | 4000 points | 5000 |
| Tier 2 | 2000 points | 8000 points | 10000 |
| Tier 3 | 4000 points | 16000 points | 20000 |
| Tier 4 | 8000 points | 32,000 points | 40000 |
| Tier 5 | 16,000 points | 64,000 points | 80000 |

The "Qualified Bonus" is granted once the referred user completes at least 100 hours of recording (Roughly 4 days of background training)

NOTE: We allow 1 account per individual. The use of bots are strictly prohibited. Please read our Community Terms of Use for more information.

Quests (Spreading the Word)

- The community is also incentivised to spread the word about the Action Model and what we stand for  
- The larger the community, the faster we grow  
- You can perform tasks and quests by visiting:  
- [train.actionmodel.com/quests](http://train.actionmodel.com/quests) 








## Token Economics (tokenomics/token-economics) {#token-economics-(tokenomics/token-economics)}

Deflationary Model / Token Buy-back and Burn (tokenomics/DeflationaryModel.mdx)

**Token Allocations**

|  | Token Allocation | % |
| :---- | ----- | ----- |
| **Community** |  |  |
| **Total Community** | **350,000,000** | **35.00%** |
|  |  |  |
| **Ecosystem Growth** |  |  |
| **Total Foundation & Ecosystem** | **225,000,000** | **22.50%** |
|  |  |  |
| **Investors** |  |  |
| **Total Investors** | **225,000,000** | **22.50%** |
|  |  |  |
| **Foundation** |  |  |
| **Total Foundation** | **200,000,000** | **20.00%** |
|  |  |  |
| **TOTAL TOKENS** | **1,000,000,000** | **100.00%** |

Certain token allocations will have vesting and lockup periods extending several years.

The Community Tokens will be released on an annual basis according to the following breakdown.

| Community Release Schedule | Allocation |
| :---- | ----- |
| **Year 1** | 30% |
| **Year 2** | 30% |
| **Year 3** | 20% |
| **Year 4** | 20% |

**Points \-\> Tokens**  
Initially, prior to TGE, users will receive points.

These points will convert to tokens at the TGE. Community tokens released to contributors will initially for deployment of Fuel within the Actionist Agents.





